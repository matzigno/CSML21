{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data management\n",
    "import pandas as pd\n",
    "\n",
    "# Data preprocessing and trasformation (ETL)\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, FunctionTransformer, Binarizer, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Math and Stat modules\n",
    "import numpy as np\n",
    "\n",
    "# Supervised Learning\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Unsupervised Learning\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepariamo velocemente i dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_data = pd.read_csv('BankChurnersMissingData.csv')\n",
    "credit_card_data.dropna(subset=['Total_Revolving_Bal','Months_Inactive_12_mon'],\n",
    "                   inplace=True\n",
    "                  )\n",
    "\n",
    "# Estraggo la  colonna delle label e la rimuovo dal dataset\n",
    "credit_card_label = credit_card_data['Attrition_Flag'].map(\n",
    "    {'Existing Customer':0,\n",
    "     'Attrited Customer':1\n",
    "    }\n",
    ").values\n",
    "credit_card_data.drop(columns=['Attrition_Flag',\n",
    "                               'CLIENTNUM',\n",
    "                               'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2',\n",
    "                               'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1'],\n",
    "                      inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unknown_imputer(X, missing_value = 'Unknown'):\n",
    "    X = X.values\n",
    "    unique_values, count = np.unique(X,return_counts=True)\n",
    "    num_nan = count[unique_values == missing_value]\n",
    "    counting = count[unique_values != missing_value]\n",
    "    values = unique_values[unique_values != missing_value]\n",
    "    X_new = X.copy()\n",
    "    freq = counting / np.sum(counting)\n",
    "    X_new[X_new == missing_value] = np.random.choice(values,size=num_nan,p=freq)\n",
    "    return X_new\n",
    "\n",
    "ui = FunctionTransformer(unknown_imputer)\n",
    "\n",
    "customer_age_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "category_pipeline = Pipeline([\n",
    "    ('imputer', FunctionTransformer(unknown_imputer)),\n",
    "    ('ordinal', OneHotEncoder())\n",
    "])\n",
    "\n",
    "features_robust = ['Credit_Limit','Total_Revolving_Bal','Avg_Open_To_Buy']\n",
    "features_standard = list(set(credit_card_data.select_dtypes(include=['int64','float64']).columns).difference(set(features_robust + ['Avg_Utilization_Ratio', 'Customer_Age'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessing = ColumnTransformer([\n",
    "    ('age', customer_age_pipeline, ['Customer_Age']),\n",
    "    ('gender', OrdinalEncoder(categories=[['M','F']]), ['Gender']),\n",
    "    ('edu', category_pipeline, ['Education_Level']),\n",
    "    ('status', category_pipeline, ['Marital_Status']),\n",
    "    ('income', category_pipeline, ['Income_Category']),\n",
    "    ('card', category_pipeline, ['Card_Category']),\n",
    "    ('numeric_robust', RobustScaler(), features_robust),\n",
    "    ('feature_standard', StandardScaler(), features_standard)\n",
    "],\n",
    "    remainder = 'passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = data_preprocessing.fit_transform(credit_card_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = ['Customer_Age','Gender']\n",
    "for c in ['Education_Level','Marital_Status','Income_Category']:\n",
    "    cat_inc_name = [c+'_cat{}'.format(i) for i in range(1,len(credit_card_data[c].unique()))]\n",
    "    columns_name.extend(cat_inc_name)\n",
    "columns_name.extend(['Card_Category_cat{}'.format(i) for i in range(1,len(credit_card_data['Card_Category'].unique())+1)])\n",
    "columns_name.extend(features_robust)\n",
    "columns_name.extend(features_standard)\n",
    "columns_name.append('Avg_Utilization_Ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificazione\n",
    "\n",
    "Ora siamo pronti per addestrare un modello ML e lo potremmo fare piuttosto facilmente grazie al fatto che abbiamo gia' preparato i dati e alla struttura di SKL.\n",
    "\n",
    "Iniziamo ad addestrare un Perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(feature_matrix, credit_card_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo come si comporta con alcuni elementi del training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True label: 0 vs Predicted Label: 0\n",
      "1 True label: 0 vs Predicted Label: 0\n",
      "2 True label: 0 vs Predicted Label: 0\n",
      "3 True label: 0 vs Predicted Label: 0\n",
      "4 True label: 0 vs Predicted Label: 0\n",
      "5 True label: 0 vs Predicted Label: 0\n",
      "6 True label: 0 vs Predicted Label: 0\n",
      "7 True label: 0 vs Predicted Label: 0\n",
      "8 True label: 0 vs Predicted Label: 0\n",
      "9 True label: 0 vs Predicted Label: 0\n"
     ]
    }
   ],
   "source": [
    "sample_training = feature_matrix[:10,:]\n",
    "sample_labels = credit_card_label[:10]\n",
    "prediction_sample = perceptron.predict(sample_training)\n",
    "for i in range(len(sample_labels)):\n",
    "    print(i,'True label: {} vs Predicted Label: {}'.format(sample_labels[i],prediction_sample[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un risultato che potrebbe sembrare incoraggiante...\n",
    "\n",
    "Proviamo a contare quante volte sbaglio su un set di dati gia' visto...\n",
    "\n",
    "E' fondamentale, infatti, determinare/stimare le performance del modello su un insieme di dati mai visto prima. In precedenza non abbiamo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted = perceptron.predict(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8594567901234568"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(all_predicted == credit_card_label)/len(all_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non sembra male, ma ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8393086419753086"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predicted_dummy = np.zeros(len(credit_card_label))\n",
    "np.sum(all_predicted_dummy == credit_card_label)/len(all_predicted_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il perceptron performance un po' meglio di un modello \"in tilt\".\n",
    "\n",
    "Questa piccola differenza di performance ci permette di introdurre alcune trappole in cui siamo caduti. \n",
    "1) La valutazione delle performance deve essere effettuata su dati non ancora 'visti' dall'algoritmo di apprendimento (errore metodologico)\n",
    "2) La valutazione deve tenere conto del bilanciamento o meno delle classi\n",
    "\n",
    "In questa fase, esploriamo il primo problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "Le metodologie di cross-validation possono essere utili per ottenere delle valutazioni piu' attendibili circa le proprieta' di generalizzazione del modello appreso, cioe' quanto il modello sara' in grado di predirre correttamente la classe di appartenenza su dati non ancora osservati.\n",
    "\n",
    "Per prevenire "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measure for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
